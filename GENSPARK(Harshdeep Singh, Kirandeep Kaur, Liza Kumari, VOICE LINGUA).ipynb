{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RhRhDajy8Qif",
        "outputId": "6be0de38-034c-4417-8bd7-0f5a5c6b42a6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langid in /usr/local/lib/python3.10/dist-packages (1.1.6)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from langid) (1.25.2)\n",
            "Requirement already satisfied: moviepy in /usr/local/lib/python3.10/dist-packages (1.0.3)\n",
            "Requirement already satisfied: decorator<5.0,>=4.0.2 in /usr/local/lib/python3.10/dist-packages (from moviepy) (4.4.2)\n",
            "Requirement already satisfied: tqdm<5.0,>=4.11.2 in /usr/local/lib/python3.10/dist-packages (from moviepy) (4.66.4)\n",
            "Requirement already satisfied: requests<3.0,>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from moviepy) (2.31.0)\n",
            "Requirement already satisfied: proglog<=1.0.0 in /usr/local/lib/python3.10/dist-packages (from moviepy) (0.1.10)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.10/dist-packages (from moviepy) (1.25.2)\n",
            "Requirement already satisfied: imageio<3.0,>=2.5 in /usr/local/lib/python3.10/dist-packages (from moviepy) (2.31.6)\n",
            "Requirement already satisfied: imageio-ffmpeg>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from moviepy) (0.5.1)\n",
            "Requirement already satisfied: pillow<10.1.0,>=8.3.2 in /usr/local/lib/python3.10/dist-packages (from imageio<3.0,>=2.5->moviepy) (9.4.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from imageio-ffmpeg>=0.2.0->moviepy) (67.7.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0,>=2.8.1->moviepy) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0,>=2.8.1->moviepy) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0,>=2.8.1->moviepy) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0,>=2.8.1->moviepy) (2024.7.4)\n",
            "Requirement already satisfied: ffmpeg-python in /usr/local/lib/python3.10/dist-packages (0.2.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.10/dist-packages (from ffmpeg-python) (0.18.3)\n",
            "Requirement already satisfied: deep-translator in /usr/local/lib/python3.10/dist-packages (1.11.4)\n",
            "Requirement already satisfied: beautifulsoup4<5.0.0,>=4.9.1 in /usr/local/lib/python3.10/dist-packages (from deep-translator) (4.12.3)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.23.0 in /usr/local/lib/python3.10/dist-packages (from deep-translator) (2.31.0)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4<5.0.0,>=4.9.1->deep-translator) (2.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.23.0->deep-translator) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.23.0->deep-translator) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.23.0->deep-translator) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.23.0->deep-translator) (2024.7.4)\n",
            "Requirement already satisfied: gtts in /usr/local/lib/python3.10/dist-packages (2.5.1)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.10/dist-packages (from gtts) (2.31.0)\n",
            "Requirement already satisfied: click<8.2,>=7.1 in /usr/local/lib/python3.10/dist-packages (from gtts) (8.1.7)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->gtts) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->gtts) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->gtts) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->gtts) (2024.7.4)\n",
            "Requirement already satisfied: pyttsx3 in /usr/local/lib/python3.10/dist-packages (2.90)\n",
            "Requirement already satisfied: gtts_token in /usr/local/lib/python3.10/dist-packages (1.1.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from gtts_token) (2.31.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->gtts_token) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->gtts_token) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->gtts_token) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->gtts_token) (2024.7.4)\n"
          ]
        }
      ],
      "source": [
        "!pip install --q streamlit\n",
        "!pip install langid\n",
        "!pip install moviepy\n",
        "!pip install ffmpeg-python\n",
        "!pip install deep-translator\n",
        "!pip install gtts\n",
        "!pip install pyttsx3\n",
        "!pip install gtts_token"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "32PZ3BGi8ZxC",
        "outputId": "b7fe8790-8602-42c3-aa6e-b73f2b1a0d6f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting app.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile app.py\n",
        "import streamlit as st\n",
        "import torch\n",
        "from transformers import AutoModelForSpeechSeq2Seq, AutoProcessor, pipeline\n",
        "import langid\n",
        "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
        "from deep_translator import GoogleTranslator\n",
        "from gtts import gTTS\n",
        "import os\n",
        "from moviepy.editor import VideoFileClip\n",
        "\n",
        "st.set_page_config(page_title=\"VOICE-LINGUA\", page_icon=\":microphone:\")\n",
        "\n",
        "primary_color = \"#0072C6\"  # Blue\n",
        "secondary_color = \"#F5F5F5\"  # Light gray\n",
        "background_color = \"#FFFF00\"  # White\n",
        "\n",
        "st.markdown(\n",
        "    f\"\"\"\n",
        "    <style>\n",
        "    .reportview-container {{\n",
        "        background-color: {background_color}\n",
        "    }}\n",
        "    h1 {{\n",
        "        color: {primary_color};\n",
        "    }}\n",
        "    .stFileUploader {{\n",
        "        color: {primary_color};\n",
        "    }}\n",
        "    .stHeader {{\n",
        "        color: {primary_color};\n",
        "    }}\n",
        "    </style>\n",
        "    \"\"\",\n",
        "    unsafe_allow_html=True\n",
        ")\n",
        "\n",
        "with st.sidebar:\n",
        "    st.image(\"/content/logo.png\")\n",
        "    st.title(\"VOICE-LINGUA\")\n",
        "    if \"option\" not in st.session_state:\n",
        "        st.session_state.option = \"Speech Recognition\"\n",
        "    option = st.radio(\"Select an option:\", (\"Speech Recognition\", \"Translation\", \" Speech Generation\", \"Audio Extraction\",\"Summarization\"), key=\"option\")\n",
        "\n",
        "lang_code_mapping = {\n",
        "    \"en\": \"eng_Latn\",   # English\n",
        "    \"hi\": \"hin_Deva\",   # Hindi\n",
        "    \"fr\": \"fra_Latn\",   # French\n",
        "    \"de\": \"deu_Latn\",   # German\n",
        "    \"es\": \"spa_Latn\",   # Spanish\n",
        "    \"it\": \"ita_Latn\",   # Italian\n",
        "    \"pt\": \"por_Latn\",   # Portuguese\n",
        "    \"ru\": \"rus_Cyrl\",   # Russian\n",
        "    \"ja\": \"jpn_Jpan\",   # Japanese\n",
        "    \"ko\": \"kor_Hang\",   # Korean\n",
        "    \"zh\": \"chi_Hans\",   # Simplified Chinese\n",
        "    \"ar\": \"ara_Arab\",   # Arabic\n",
        "    \"tr\": \"tur_Latn\",   # Turkish\n",
        "    \"nl\": \"nld_Latn\",   # Dutch\n",
        "    \"pl\": \"pol_Latn\",   # Polish\n",
        "    \"uk\": \"ukr_Cyrl\",   # Ukrainian\n",
        "    \"vi\": \"vie_Latn\",   # Vietnamese\n",
        "    \"th\": \"tha_Thai\",   # Thai\n",
        "    \"id\": \"ind_Latn\",   # Indonesian\n",
        "    \"ms\": \"mal_Mlym\",   # Malay\n",
        "    \"ta\": \"tam_Taml\",   # Tamil\n",
        "    \"te\": \"tel_Telu\",   # Telugu\n",
        "    \"mr\": \"mar_Deva\",   # Marathi\n",
        "    \"bn\": \"ben_Beng\",   # Bengali\n",
        "    \"gu\": \"guj_Gujr\",   # Gujarati\n",
        "    \"kn\": \"kan_Knda\",   # Kannada\n",
        "    \"pa\": \"pan_Guru\",   # Punjabi\n",
        "    \"ur\": \"urd_Arab\",   # Urdu\n",
        "    \"si\": \"sin_Sinh\",   # Sinhala\n",
        "    \"mt\": \"mlt_Latn\",   # Maltese\n",
        "    \"fi\": \"fin_Latn\",   # Finnish\n",
        "    \"sv\": \"swe_Latn\",   # Swedish\n",
        "    \"da\": \"dan_Latn\",   # Danish\n",
        "    \"no\": \"nor_Latn\",   # Norwegian\n",
        "    \"hu\": \"hun_Latn\",   # Hungarian\n",
        "    \"he\": \"heb_Hebr\",   # Hebrew\n",
        "    \"el\": \"ell_Grek\",   # Greek\n",
        "    \"ro\": \"rom_Latn\",   # Romanian\n",
        "    \"bg\": \"bul_Cyrl\",   # Bulgarian\n",
        "    \"sr\": \"srp_Cyrl\",   # Serbian\n",
        "    \"cs\": \"ces_Latn\",   # Czech\n",
        "    \"sk\": \"slk_Latn\",   # Slovak\n",
        "    \"hr\": \"hrv_Latn\",   # Croatian\n",
        "    \"fa\": \"pes_Arab\",   # Persian\n",
        "    \"lt\": \"lit_Latn\",   # Lithuanian\n",
        "    \"lv\": \"lav_Latn\",   # Latvian\n",
        "    \"et\": \"est_Latn\",   # Estonian\n",
        "    \"sw\": \"swa_Latn\",   # Swahili\n",
        "    \"sl\": \"slv_Latn\"    # Slovenian\n",
        "}\n",
        "\n",
        "\n",
        "lang_code_mapping2 = {\n",
        "    \"en\": \"en\",   # English\n",
        "    \"hi\": \"hi\",   # Hindi\n",
        "    \"fr\": \"fr\",   # French\n",
        "    \"de\": \"de\",   # German\n",
        "    \"es\": \"es\",   # Spanish\n",
        "    \"it\": \"it\",   # Italian\n",
        "    \"pt\": \"pt\",   # Portuguese\n",
        "    \"ru\": \"ru\",   # Russian\n",
        "    \"ja\": \"ja\",   # Japanese\n",
        "    \"ko\": \"ko\",   # Korean\n",
        "    \"zh\": \"zh\",   # Simplified Chinese\n",
        "    \"ar\": \"ar\",   # Arabic\n",
        "    \"tr\": \"tr\",   # Turkish\n",
        "    \"nl\": \"nl\",   # Dutch\n",
        "    \"pl\": \"pl\",   # Polish\n",
        "    \"uk\": \"uk\",   # Ukrainian\n",
        "    \"vi\": \"vi\",   # Vietnamese\n",
        "    \"th\": \"th\",   # Thai\n",
        "    \"id\": \"id\",   # Indonesian\n",
        "    \"ms\": \"ms\",   # Malay\n",
        "    \"ta\": \"ta\",   # Tamil\n",
        "    \"te\": \"te\",   # Telugu\n",
        "    \"mr\": \"mr\",   # Marathi\n",
        "    \"bn\": \"bn\",   # Bengali\n",
        "    \"gu\": \"gu\",   # Gujarati\n",
        "    \"kn\": \"kn\",   # Kannada\n",
        "    \"pa\": \"pa\",   # Punjabi\n",
        "    \"ur\": \"ur\",   # Urdu\n",
        "    \"si\": \"si\",   # Sinhala\n",
        "    \"mt\": \"mt\",   # Maltese\n",
        "    \"fi\": \"fi\",   # Finnish\n",
        "    \"sv\": \"sv\",   # Swedish\n",
        "    \"da\": \"da\",   # Danish\n",
        "    \"no\": \"no\",   # Norwegian\n",
        "    \"hu\": \"hu\",   # Hungarian\n",
        "    \"he\": \"he\",   # Hebrew\n",
        "    \"el\": \"el\",   # Greek\n",
        "    \"ro\": \"ro\",   # Romanian\n",
        "    \"bg\": \"bg\",   # Bulgarian\n",
        "    \"sr\": \"sr\",   # Serbian\n",
        "    \"cs\": \"cs\",   # Czech\n",
        "    \"sk\": \"sk\",   # Slovak\n",
        "    \"hr\": \"hr\",   # Croatian\n",
        "    \"fa\": \"fa\",   # Persian\n",
        "    \"lt\": \"lt\",   # Lithuanian\n",
        "    \"lv\": \"lv\",   # Latvian\n",
        "    \"et\": \"et\",   # Estonian\n",
        "    \"sw\": \"sw\",   # Swahili\n",
        "    \"sl\": \"sl\"    # Slovenian\n",
        "}\n",
        "\n",
        "def detect_language_nllb(text):\n",
        "    # Detect language using langid\n",
        "    lang_code, _ = langid.classify(text)\n",
        "    print(f\"Detected Language Code: {lang_code}\")\n",
        "\n",
        "    nllb_code = lang_code_mapping.get(lang_code, \"eng_Latn\")  # Default to \"eng_Latn\" if not found\n",
        "    return nllb_code\n",
        "\n",
        "def translate_and_generate_audio(text, target_lang, filename):\n",
        "\n",
        "    translator = GoogleTranslator(source='auto', target=target_lang)\n",
        "    translated_text = translator.translate(text)\n",
        "    tts = gTTS(text=translated_text, lang=target_lang)\n",
        "    tts.save(filename)\n",
        "    print(f\"Audio file saved as: {filename}\")\n",
        "\n",
        "if option == \"Speech Recognition\":\n",
        "\n",
        "    st.title(\"Speech Recognition\")\n",
        "    st.subheader(\"Upload an audio file to transcribe:\")\n",
        "\n",
        "    if \"uploaded_file\" not in st.session_state:\n",
        "        st.session_state.uploaded_file = None\n",
        "\n",
        "    uploaded_file = st.file_uploader(\"\", type=[\"wav\", \"mp3\", \"m4a\", \"mpeg\"], key=\"speech_to_text\")\n",
        "\n",
        "    if uploaded_file is not None:\n",
        "        st.session_state.uploaded_file = uploaded_file\n",
        "    else:\n",
        "        uploaded_file = st.session_state.get(\"uploaded_file\", None)\n",
        "\n",
        "    if uploaded_file is not None:\n",
        "        with open(\"uploaded_audio.wav\", \"wb\") as f:\n",
        "            f.write(uploaded_file.getbuffer())\n",
        "\n",
        "        st.audio(uploaded_file, format=\"audio/wav\")\n",
        "\n",
        "        device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
        "        torch_dtype = torch.float16 if torch.cuda.is_available() else torch.float32\n",
        "        model_id = \"openai/whisper-large-v3\"\n",
        "\n",
        "        model = AutoModelForSpeechSeq2Seq.from_pretrained(\n",
        "            model_id,\n",
        "            torch_dtype=torch_dtype,\n",
        "            use_safetensors=True\n",
        "        )\n",
        "        model.to(device)\n",
        "\n",
        "        processor = AutoProcessor.from_pretrained(model_id)\n",
        "        pipe = pipeline(\n",
        "            \"automatic-speech-recognition\",\n",
        "            model=model,\n",
        "            tokenizer=processor.tokenizer,\n",
        "            feature_extractor=processor.feature_extractor,\n",
        "            max_new_tokens=128,\n",
        "            chunk_length_s=15,\n",
        "            batch_size=16,\n",
        "            return_timestamps=True,\n",
        "            torch_dtype=torch_dtype,\n",
        "            device=device,\n",
        "        )\n",
        "\n",
        "        def transcribe_audio(audio):\n",
        "            result = pipe(audio)\n",
        "            transcript = result['text']\n",
        "            return transcript\n",
        "\n",
        "        transcript = transcribe_audio(\"uploaded_audio.wav\")\n",
        "\n",
        "        # Detect language of the transcribed text\n",
        "        nllb_lang_code = detect_language_nllb(transcript)\n",
        "        print(f\"NLLB-200 Language Code: {nllb_lang_code}\")\n",
        "\n",
        "        st.header(\"Transcription:\")\n",
        "        st.write(transcript)\n",
        "        st.subheader(\"Language Code:\")\n",
        "        st.write(nllb_lang_code)\n",
        "\n",
        "elif option == \"Translation\":\n",
        "\n",
        "    st.title(\"Translation\")\n",
        "    st.subheader(\"Translate text from one language to another:\")\n",
        "\n",
        "    if \"input_text\" not in st.session_state:\n",
        "        st.session_state.input_text = \"\"\n",
        "\n",
        "    if \"src_lang\" not in st.session_state:\n",
        "        st.session_state.src_lang = \"en\"\n",
        "\n",
        "    if \"target_lang\" not in st.session_state:\n",
        "        st.session_state.target_lang = \"en\"\n",
        "\n",
        "    input_text = st.text_area(\"Enter text to translate:\", value=st.session_state.input_text, key=\"translation_input\")\n",
        "    src_lang = st.selectbox(\"Select source language:\", list(lang_code_mapping.keys()), index=list(lang_code_mapping.keys()).index(st.session_state.src_lang), key=\"translation_src_lang\")\n",
        "    target_lang = st.selectbox(\"Select target language:\", list(lang_code_mapping.keys()), index=list(lang_code_mapping.keys()).index(st.session_state.target_lang), key=\"translation_target_lang\")\n",
        "\n",
        "    if st.button(\"Translate\"):\n",
        "        st.session_state.input_text = input_text\n",
        "        st.session_state.src_lang = src_lang\n",
        "        st.session_state.target_lang = target_lang\n",
        "\n",
        "        src_lang_code = lang_code_mapping[src_lang]\n",
        "        target_lang_code = lang_code_mapping[target_lang]\n",
        "\n",
        "        tokenizer = AutoTokenizer.from_pretrained(\"facebook/nllb-200-distilled-600M\")\n",
        "        model = AutoModelForSeq2SeqLM.from_pretrained(\"facebook/nllb-200-distilled-600M\")\n",
        "\n",
        "        def translate_text(input_text, src_lang_code, target_lang_code):\n",
        "            translator = pipeline('translation', model=model, tokenizer=tokenizer, src_lang=src_lang_code, tgt_lang=target_lang_code)\n",
        "            translated_text = translator(input_text)[0]['translation_text']\n",
        "            return translated_text\n",
        "\n",
        "        output_text = translate_text(input_text, src_lang_code, target_lang_code)\n",
        "\n",
        "        st.header(\"Translated Text:\")\n",
        "        st.write(output_text)\n",
        "\n",
        "elif option == \" Speech Generation\":\n",
        "    st.title(\" Speech Generation\")\n",
        "    st.subheader(\"Translate text and generate audio in the target language:\")\n",
        "\n",
        "    if \"input_text\" not in st.session_state:\n",
        "        st.session_state.input_text = \"\"\n",
        "\n",
        "    if \"target_lang\" not in st.session_state:\n",
        "        st.session_state.target_lang = \"en\"\n",
        "\n",
        "    input_text = st.text_area(\"Enter text to translate:\", value=st.session_state.input_text, key=\"translation_input\")\n",
        "    target_lang = st.selectbox(\"Select target language:\", list(lang_code_mapping2.keys()), index=list(lang_code_mapping2.keys()).index(st.session_state.target_lang), key=\"translation_target_lang2\")\n",
        "\n",
        "    if st.button(\"Speech Generation\"):\n",
        "        st.session_state.input_text = input_text\n",
        "        st.session_state.target_lang = target_lang\n",
        "\n",
        "        if target_lang in lang_code_mapping2:\n",
        "            target_lang_code2 = lang_code_mapping2[target_lang]\n",
        "        else:\n",
        "            st.error(\"Invalid language code. Please select a valid target language.\")\n",
        "\n",
        "\n",
        "        filename = \"output.mp3\"\n",
        "        translate_and_generate_audio(input_text, target_lang_code2, filename)\n",
        "\n",
        "        st.success(\"Audio file generated successfully!\")\n",
        "        st.audio(filename, format=\"audio/mp3\")\n",
        "\n",
        "elif option == \"Audio Extraction\":\n",
        "\n",
        "    st.title(\"Audio Extraction\")\n",
        "    st.subheader(\"Extract audio from a video file:\")\n",
        "\n",
        "    video_file = st.text_input(\"Enter the path to the video file:\", key=\"video_file\")\n",
        "\n",
        "    if st.button(\"Extract Audio\"):\n",
        "\n",
        "        import os\n",
        "        if not os.path.isfile(video_file):\n",
        "            st.error(\"Error: The provided path is not a file.\")\n",
        "        else:\n",
        "            # Load the video file\n",
        "            video = VideoFileClip(video_file)\n",
        "\n",
        "            # Extract the audio from the video\n",
        "            audio = video.audio\n",
        "\n",
        "            # Write the audio to a file\n",
        "            audio_file = \"output_audio.mp3\"\n",
        "            audio.write_audiofile(audio_file)\n",
        "\n",
        "            st.success(\"Audio extracted successfully!\")\n",
        "\n",
        "            download_audio = st.button(\"Download the extracted audio file\")\n",
        "            if download_audio:\n",
        "\n",
        "                with open(audio_file, \"rb\") as file:\n",
        "\n",
        "                    audio_data = file.read()\n",
        "\n",
        "                st.markdown(f\"Content-Type: audio/mpeg\")\n",
        "                st.markdown(f\"Content-Disposition: attachment; filename={audio_file}\")\n",
        "                st.markdown(f\"Content-Length: {len(audio_data)}\")\n",
        "                st.write(audio_data)\n",
        "            else:\n",
        "                st.info(\"Audio file not downloaded.\")\n",
        "elif option == \"Summarization\":\n",
        "    st.title(\"Text Summarizer\")\n",
        "\n",
        "    input_text = st.text_area(\"Enter the text to summarize:\", height=200)\n",
        "    input_text_words = input_text.split()\n",
        "    st.subheader(\"Number of words in the input text:\")\n",
        "    st.write(len(input_text_words))\n",
        "\n",
        "    min1 = max(10, int(len(input_text_words) / 3))  # Ensure min1 is at least 10\n",
        "    max1 = int(len(input_text_words) / 2)\n",
        "    min2 = int(len(input_text_words) / 2)\n",
        "    max2 = len(input_text_words)\n",
        "\n",
        "    min_length = st.slider(\"Choose the minimum summary length\", min_value=min1, max_value=max1, value=min1, step=5)\n",
        "    max_length = st.slider(\"Choose the maximum summary length\", min_value=min2, max_value=max2, value=max2, step=10)\n",
        "\n",
        "    if st.button(\"Summarize\"):\n",
        "        summarizer = pipeline('summarization', model='sshleifer/distilbart-cnn-12-6')\n",
        "        summary = summarizer(input_text, max_length=max_length, min_length=min_length, do_sample=False)[0]['summary_text']\n",
        "        st.subheader(\"Summary:\")\n",
        "        st.write(summary)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kiKtKSUy83O8",
        "outputId": "947a44ce-6867-40a9-ddb4-f8df9b25d67f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "34.19.67.123\n"
          ]
        }
      ],
      "source": [
        "! wget -q -O - ipv4.icanhazip.com"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mFyz1vn_86Ib",
        "outputId": "96a0a11e-d26f-4aa0-a10c-9c5d219530ad"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Collecting usage statistics. To deactivate, set browser.gatherUsageStats to false.\n",
            "\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m\u001b[1m  You can now view your Streamlit app in your browser.\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m  Local URL: \u001b[0m\u001b[1mhttp://localhost:8501\u001b[0m\n",
            "\u001b[34m  Network URL: \u001b[0m\u001b[1mhttp://172.28.0.12:8501\u001b[0m\n",
            "\u001b[34m  External URL: \u001b[0m\u001b[1mhttp://34.19.67.123:8501\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[K\u001b[?25hnpx: installed 22 in 5.796s\n",
            "your url is: https://eight-lines-own.loca.lt\n",
            "2024-07-18 05:47:25.357383: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-07-18 05:47:25.357428: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-07-18 05:47:25.358833: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-07-18 05:47:25.367192: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2024-07-18 05:47:26.479734: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "error: XDG_RUNTIME_DIR not set in the environment.\n",
            "ALSA lib confmisc.c:855:(parse_card) cannot find card '0'\n",
            "ALSA lib conf.c:5178:(_snd_config_evaluate) function snd_func_card_inum returned error: No such file or directory\n",
            "ALSA lib confmisc.c:422:(snd_func_concat) error evaluating strings\n",
            "ALSA lib conf.c:5178:(_snd_config_evaluate) function snd_func_concat returned error: No such file or directory\n",
            "ALSA lib confmisc.c:1334:(snd_func_refer) error evaluating name\n",
            "ALSA lib conf.c:5178:(_snd_config_evaluate) function snd_func_refer returned error: No such file or directory\n",
            "ALSA lib conf.c:5701:(snd_config_expand) Evaluate error: No such file or directory\n",
            "ALSA lib pcm.c:2664:(snd_pcm_open_noupdate) Unknown PCM default\n",
            "ALSA lib confmisc.c:855:(parse_card) cannot find card '0'\n",
            "ALSA lib conf.c:5178:(_snd_config_evaluate) function snd_func_card_inum returned error: No such file or directory\n",
            "ALSA lib confmisc.c:422:(snd_func_concat) error evaluating strings\n",
            "ALSA lib conf.c:5178:(_snd_config_evaluate) function snd_func_concat returned error: No such file or directory\n",
            "ALSA lib confmisc.c:1334:(snd_func_refer) error evaluating name\n",
            "ALSA lib conf.c:5178:(_snd_config_evaluate) function snd_func_refer returned error: No such file or directory\n",
            "ALSA lib conf.c:5701:(snd_config_expand) Evaluate error: No such file or directory\n",
            "ALSA lib pcm.c:2664:(snd_pcm_open_noupdate) Unknown PCM default\n",
            "2024-07-18 05:47:30.971 `label` got an empty value. This is discouraged for accessibility reasons and may be disallowed in the future by raising an exception. Please provide a non-empty label and hide it with label_visibility if needed.\n",
            "2024-07-18 05:53:59.430 `label` got an empty value. This is discouraged for accessibility reasons and may be disallowed in the future by raising an exception. Please provide a non-empty label and hide it with label_visibility if needed.\n",
            "2024-07-18 05:54:37.829 `label` got an empty value. This is discouraged for accessibility reasons and may be disallowed in the future by raising an exception. Please provide a non-empty label and hide it with label_visibility if needed.\n",
            "config.json: 100% 1.27k/1.27k [00:00<00:00, 7.55MB/s]\n",
            "model.safetensors: 100% 3.09G/3.09G [00:17<00:00, 173MB/s]\n",
            "generation_config.json: 100% 3.90k/3.90k [00:00<00:00, 23.9MB/s]\n",
            "preprocessor_config.json: 100% 340/340 [00:00<00:00, 3.16MB/s]\n",
            "tokenizer_config.json: 100% 283k/283k [00:00<00:00, 4.47MB/s]\n",
            "vocab.json: 100% 1.04M/1.04M [00:00<00:00, 3.97MB/s]\n",
            "tokenizer.json: 100% 2.48M/2.48M [00:00<00:00, 12.9MB/s]\n",
            "merges.txt: 100% 494k/494k [00:00<00:00, 29.6MB/s]\n",
            "normalizer.json: 100% 52.7k/52.7k [00:00<00:00, 169MB/s]\n",
            "added_tokens.json: 100% 34.6k/34.6k [00:00<00:00, 155MB/s]\n",
            "special_tokens_map.json: 100% 2.07k/2.07k [00:00<00:00, 20.0MB/s]\n",
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
            "Due to a bug fix in https://github.com/huggingface/transformers/pull/28687 transcription using a multilingual Whisper will default to language detection followed by transcription instead of translation to English.This might be a breaking change for your use case. If you want to instead always translate your audio to English, make sure to pass `language='en'`.\n",
            "The attention mask is not set and cannot be inferred from input because pad token is same as eos token.As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Detected Language Code: en\n",
            "NLLB-200 Language Code: eng_Latn\n",
            "2024-07-18 05:59:50.036 `label` got an empty value. This is discouraged for accessibility reasons and may be disallowed in the future by raising an exception. Please provide a non-empty label and hide it with label_visibility if needed.\n",
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
            "Detected Language Code: en\n",
            "NLLB-200 Language Code: eng_Latn\n",
            "\u001b[34m  Stopping...\u001b[0m\n",
            "^C\n"
          ]
        }
      ],
      "source": [
        "! streamlit run app.py & npx localtunnel --port 8501"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}